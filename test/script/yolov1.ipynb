{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import renom as rm\n",
    "from renom_img.api.detection.yolo_v1 import Yolov1\n",
    "from renom_img.api.utility.load import parse_xml_detection, load_img\n",
    "from renom.cuda import set_cuda_active\n",
    "set_cuda_active(True)\n",
    "from renom_img.api.utility.augmentation import Augmentation\n",
    "from renom_img.api.utility.augmentation.process import *\n",
    "from renom_img.api.utility.evaluate import EvaluatorDetection\n",
    "from renom_img.api.utility.distributor.distributor import ImageDistributor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(datetime.date(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(filename):\n",
    "    ann=[]\n",
    "    img_path=[]\n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            line = line[:-1]\n",
    "            line = \"/mnt/research/dataset/VOCdevkit/\"+line\n",
    "            img_path.append(line)\n",
    "            line = line.replace('JPEGImages','Annotations')\n",
    "            line = line.replace('jpg','xml')\n",
    "            ann.append(line)\n",
    "    return img_path,ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_box(pred,actual):\n",
    "    for i in range(len(pred)):\n",
    "        h = actual[i][0]['size'][1]\n",
    "        w = actual[i][0]['size'][0]\n",
    "        if len(pred[i])>0:\n",
    "            for j in range(len(pred[i])):\n",
    "                xmin = pred[i][j]['box'][0] * w\n",
    "                ymin = pred[i][j]['box'][1] * h\n",
    "                xmax = pred[i][j]['box'][2] * w\n",
    "                ymax = pred[i][j]['box'][3] * h\n",
    "                pred[i][j]['box']=[xmin, ymin, xmax, ymax]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_function(*args):\n",
    "    if len(args)>0:\n",
    "#         calculating mAP\n",
    "        model = args[1]\n",
    "#         saving model\n",
    "        train_list = args[2]\n",
    "        validation_loss_list = args[3]\n",
    "        epoch = args[0]\n",
    "        if len(validation_loss_list)>1:\n",
    "            tmp = copy.deepcopy(validation_loss_list)\n",
    "            current_loss = tmp[-1]\n",
    "            del(tmp[-1])\n",
    "            tmp.sort()\n",
    "            if(current_loss<tmp[0]):\n",
    "                test_dist = ImageDistributor(valid_image)\n",
    "                results = []\n",
    "                for i, (x_img_list, _) in enumerate(test_dist.batch(1, shuffle=False)):\n",
    "                    img_array = np.vstack([load_img(path, model.imsize)[None]\n",
    "                                           for path in x_img_list])\n",
    "                    img_array = model.preprocess(img_array)\n",
    "                    results.extend(model.get_bbox(model(img_array).as_ndarray(),\n",
    "                                                 score_threshold=0.005, nms_threshold=0.45))\n",
    "\n",
    "                predicted = reconstruct_box(results,valid_annotation)\n",
    "                ev = EvaluatorDetection(predicted,valid_annotation)\n",
    "                fp = open('model_logs/yolov1@'+date+'.txt','a')\n",
    "                fp.write('Epoch: {:03d} Train Loss: {:3.2f}  Valid Loss: {:3.2f} mAP: {:3.2f} \\n'.format(epoch,float(train_list[-1]),float(validation_loss_list[-1]),float(ev.mAP())))\n",
    "                fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_annot = create_list(\"/mnt/research/dataset/VOCdevkit/voc_train.txt\")\n",
    "valid_image, valid_annot = create_list(\"/mnt/research/dataset/VOCdevkit/2007_test.txt\")\n",
    "\n",
    "train_annotation, cmap = parse_xml_detection(train_annot)\n",
    "valid_annotation, _ = parse_xml_detection(valid_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Augmentation([Shift(15,15),\n",
    "                    Flip(),\n",
    "                    Rotate(),\n",
    "                    ContrastNorm()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov1(cmap,load_pretrained_weight=True,train_whole_network=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_image,train_annotation,valid_image,valid_annotation,\n",
    "                epoch=160,batch_size=8,augmentation=aug,callback_end_epoch=end_function)\n",
    "fp = open('model_logs/yolov1@'+date+'.txt','a')\n",
    "fp.write('\\nSuccess')\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel2",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
