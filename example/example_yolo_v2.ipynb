{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of YOLO version 2 module.\n",
    "\n",
    "This is a example usage of YOLO version 2 module.\n",
    "\n",
    "**YOLO9000: Better, Faster, Stronger**  \n",
    "Joseph Redmon, Ali Farhadi  \n",
    "https://arxiv.org/abs/1612.08242\n",
    "\n",
    "### Over view of yolo v2\n",
    "\n",
    "First, introduces overview of YOLOv2. YOLO v2 is improved version of YOLO at detection speed, accuracy and number of avairable class.\n",
    "\n",
    "Following fugure is Convolutional neural net work used in yolo v2. This architecture is called Darknet19.\n",
    "\n",
    "Comparing to darknet which is used in YOLO v1, darknet19 has batch normalization layer after each convolution layer.\n",
    "And fully connected layers(dense layers) is removed. This allows YOLOv2 to perform object detection with multi scale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import renom as rm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from renom_img.api.detection.yolo_v2 import Yolov2, create_anchor\n",
    "from renom_img.api.utility.distributor.distributor import ImageDistributor\n",
    "from renom_img.api.utility.augmentation import Augmentation\n",
    "from renom_img.api.utility.augmentation.process import *\n",
    "from renom_img.api.utility.load import parse_xml_detection\n",
    "from renom_img.api.utility.misc.display import draw_box\n",
    "\n",
    "from renom.cuda import set_cuda_active\n",
    "set_cuda_active(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "**The PASCAL Visual Object Classes Homepage**  \n",
    "http://host.robots.ox.ac.uk/pascal/VOC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"VOCdevkit/VOC2007\"):\n",
    "    !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "    !tar xfv VOCtrainval_06-Nov-2007.tar\n",
    "    \n",
    "if not os.path.exists(\"VOCdevkit/VOC2012\"):\n",
    "    !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "    !tar xfv VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devide data into train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size\n",
      "  Train:10728\n",
      "  Valid:5823\n",
      "\n",
      "Class list\n",
      "  00 aeroplane\n",
      "  01 bicycle\n",
      "  02 bird\n",
      "  03 boat\n",
      "  04 bottle\n",
      "  05 bus\n",
      "  06 car\n",
      "  07 cat\n",
      "  08 chair\n",
      "  09 cow\n",
      "  10 diningtable\n",
      "  11 dog\n",
      "  12 horse\n",
      "  13 motorbike\n",
      "  14 person\n",
      "  15 pottedplant\n",
      "  16 sheep\n",
      "  17 sofa\n",
      "  18 train\n",
      "  19 tvmonitor\n"
     ]
    }
   ],
   "source": [
    "image_voc_2007 = \"VOCdevkit/VOC2007/JPEGImages/\"\n",
    "label_voc_2007 = \"VOCdevkit/VOC2007/Annotations/\"\n",
    "image_voc_2012 = \"VOCdevkit/VOC2012/JPEGImages/\"\n",
    "label_voc_2012 = \"VOCdevkit/VOC2012/Annotations/\"\n",
    "\n",
    "train_voc_2007 = [line.strip() for line in open(\"VOCdevkit/VOC2007/ImageSets/Main/train.txt\").readlines()]\n",
    "train_voc_2007 += [line.strip() for line in open(\"VOCdevkit/VOC2007/ImageSets/Main/val.txt\").readlines()]\n",
    "train_voc_2012 = [line.strip() for line in open(\"VOCdevkit/VOC2012/ImageSets/Main/train.txt\").readlines()]\n",
    "valid_voc_2012 = [line.strip() for line in open(\"VOCdevkit/VOC2012/ImageSets/Main/val.txt\").readlines()]\n",
    "\n",
    "train_image_path_list = []\n",
    "train_label_path_list = []\n",
    "valid_image_path_list = []\n",
    "valid_label_path_list = []\n",
    "\n",
    "# Use training dataset of VOC2007, VOC2012 and validation dataset of 2007 as training data.\n",
    "for path in train_voc_2007:\n",
    "    train_image_path_list.append(os.path.join(image_voc_2007, path+'.jpg'))\n",
    "    train_label_path_list.append(os.path.join(label_voc_2007, path+'.xml'))\n",
    "\n",
    "for path in train_voc_2012:\n",
    "    train_image_path_list.append(os.path.join(image_voc_2012, path+'.jpg'))\n",
    "    train_label_path_list.append(os.path.join(label_voc_2012, path+'.xml'))\n",
    "\n",
    "# Use validation dataset of VOC2012 as validation data.\n",
    "for path in valid_voc_2012:\n",
    "    valid_image_path_list.append(os.path.join(image_voc_2012, path+'.jpg'))\n",
    "    valid_label_path_list.append(os.path.join(label_voc_2012, path+'.xml'))\n",
    "\n",
    "train_annot, class_map = parse_xml_detection(train_label_path_list)\n",
    "valid_annot, _ = parse_xml_detection(valid_label_path_list)\n",
    "\n",
    "print(\"Dataset size\")\n",
    "print(\"  Train:{}\".format(len(train_annot)))\n",
    "print(\"  Valid:{}\\n\".format(len(valid_annot)))\n",
    "\n",
    "print(\"Class list\")\n",
    "for i, name in enumerate(class_map):\n",
    "    print(\"  {:02d} {}\".format(i, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Yolo v2 model.\n",
    "\n",
    "ReNomIMG provides yolo v2 model. \n",
    "This module requires, following arguments.\n",
    "\n",
    "- class_map (list): List of class name.\n",
    "- anchor (AnchorYolov2): Anchor. Anchor can be created using \"create_anchor\" function.\n",
    "- imsize (tuple): Image size. This is used for prediction.\n",
    "- load_pretrained_weight (bool): If this is True, pretrained weight will be downloaded and loaded.\n",
    "- train_whole_network (bool): If this is True, backpropagation will be performed through whole net work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov2(class_map=class_map,\n",
    "               anchor=create_anchor(train_annot, base_size=(416, 416)),\n",
    "               imsize=(32*10, 32*10),\n",
    "               load_pretrained_weight=True,\n",
    "               train_whole_network=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train YOLO v2 model using 'fit function'.\n",
    "\n",
    "The model object has `fit` method. It allows us to train yolo2 only giving image data path list and annotation list.\n",
    "Following arguments can be give to `fit` method.\n",
    "\n",
    "- train_img_path_list (list): Image path list used for training.\n",
    "- train_annotation_list (list): Annotation list used for training.\n",
    "- valid_img_path_list (list): Image path list used for validation.\n",
    "- valid_annotation_list (list): Annotation list used for validation.\n",
    "- epoch (int): Number of training epoch.\n",
    "- batch_size (int): Number of batch size.\n",
    "- imsize_list (list): List of image size. Image size must be muplitples of 32.\n",
    "- augmentation (Augmentation): Augmentation object.\n",
    "- callback_end_epoch (function): Given function will be called at end of epoch.\n",
    "\n",
    "Because of the fully convolutional architecture, YOLO v2 can be trained with multiple image size. Available image size is multiple of 32.\n",
    "If `imsize_list` is given, a image size will be randomly selected per each 10 batch.\n",
    "\n",
    "**Note**: Running following code with following parameters requires 11GB of GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    # Feeds image and annotation data.\n",
    "    train_image_path_list,\n",
    "    train_label_path_list,\n",
    "    valid_image_path_list,\n",
    "    valid_label_path_list,\n",
    "    epoch=8,\n",
    "    batch_size=8,\n",
    "    # Giving 11 variations of image size.\n",
    "    imsize_list=[(32*i, 32*i) for i in range(9, 20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "For using trained model, `model.predict` method can be used. This method requires following arguments.\n",
    "\n",
    "- img_list (list, ndarray): Image path, list of image path or numpy array can be given.\n",
    "\n",
    "If one image path is given, `predict` method returns following data. \n",
    "```python\n",
    "[\n",
    "    {  # 1st predicted object for input image path.\n",
    "        \"box\":[x(float), y, w, h],  \n",
    "        \"score\": confidencial_score(float),  \n",
    "        \"class\": class_id(int),  \n",
    "        \"name\": class_name(str)\n",
    "    },\n",
    "    {  # 2nd predicted object for input image path.\n",
    "        \"box\":[x(float), y, w, h],  \n",
    "        \"score\": confidencial_score(float),  \n",
    "        \"class\": class_id(int),  \n",
    "        \"name\": class_name(str)\n",
    "    },\n",
    "    ...\n",
    "]  \n",
    "```\n",
    "\n",
    "If a list of image path or numpy array is given, `predict` method returns following data. \n",
    "```python\n",
    "[\n",
    "    [ # Predictions of 1st image.\n",
    "        {  # 1st predicted object for 1st image path.\n",
    "            \"box\":[x(float), y, w, h],  \n",
    "            \"score\": confidencial_score(float),  \n",
    "            \"class\": class_id(int),  \n",
    "            \"name\": class_name(str),  \n",
    "        },\n",
    "        {  # 2nd predicted object for 1st image path.\n",
    "            \"box\":[x, y, w, h],  \n",
    "            \"score\": confidencial score(float),  \n",
    "            \"class\": class_id(int),  \n",
    "            \"name\": class_name(str),  \n",
    "        },\n",
    "    ],\n",
    "    [ # Predictions of 2nd image.\n",
    "        {  # 1st predicted object for 2nd image path.\n",
    "            \"box\":[x(float), y, w, h],  \n",
    "            \"score\": confidencial score(float),  \n",
    "            \"class\": class_id(int),  \n",
    "            \"name\": class_name(str),  \n",
    "        },\n",
    "        {  # 2nd predicted object for 2nd image path.\n",
    "            \"box\":[x, y, w, h],  \n",
    "            \"score\": confidencial score(float),  \n",
    "            \"class\": class_id(int),  \n",
    "            \"name\": class_name(str),  \n",
    "        },\n",
    "    ],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Note**: The coordinate of box repesents ratio to the image size.\n",
    "Therefore the range of predicted box coordinate is `0 <= x, y, w, h <= 1`.\n",
    "\n",
    "If you want to change detection image size, you can set the attribute `model.imsize`.\n",
    "\n",
    "ReNomIMG also provides draw bounding box function.\n",
    "`renom_img.api.utility.misc.display.draw_box` can be used for show prediction result.\n",
    "The function requires image path and prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the image size for prediction.\n",
    "# model.imsize = (32*12, 32*12)\n",
    "for i in range(40):\n",
    "    path = valid_image_path_list[i]\n",
    "    # Output of predict method can be given directly.\n",
    "    plt.imshow(draw_box(path, model.predict(path)))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
